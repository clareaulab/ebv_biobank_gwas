{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGENIE for EBV DNA GWAS\n",
    "\n",
    "This notebook is largely following the demo workspace for performing GWAS in AoU: https://workbench.researchallofus.org/workspaces/aou-rw-5981f9dc/aouldlgwasregeniedsubctv6duplicate/analysis. In particular, this is a modified version of the `4.0_regenie_dsub_HP_TM` script to run REGENIE with our EBV DNA binary trait.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Package Import\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring dsub is up to date\n",
    "! pip3 install --upgrade dsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables setup\n",
    "These steps are necessary for setting up environmental variables referenced in the main dsub script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as an environment variable so it's easier to use within %%bash cells\n",
    "%env JOB_ID={LINE_COUNT_JOB_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining necessary pathways\n",
    "my_bucket = os.environ['WORKSPACE_BUCKET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting for running dsub jobs\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "\n",
    "# Save as an environment variable so it's easier to use within %%bash cells\n",
    "%env USER_NAME={USER_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the JOB_NAME variable for the individual job names \n",
    "## NOTE: Use underscores, not whitespace, since it will become part of the bucket path\n",
    "JOB_NAME='EBV_DNA' ## add name in quotes, copy name in quotes to 4.1\n",
    "\n",
    "# Save as an environment variable so it's easier to use within %%bash cells\n",
    "%env JOB_NAME={JOB_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up analysis results folder\n",
    "line_count_results_folder = os.path.join(\n",
    "    os.getenv('WORKSPACE_BUCKET'),\n",
    "    'dsub',\n",
    "    'results',\n",
    "    JOB_NAME,\n",
    "    USER_NAME,\n",
    "    datetime.now().strftime('%Y%m%d'))\n",
    "\n",
    "line_count_results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for saving output files\n",
    "output_files = os.path.join(line_count_results_folder, \"results\")\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILES = output_files\n",
    "\n",
    "# Save as an environment variable so it's easier to use within %%bash cells\n",
    "%env OUTPUT_FILES={OUTPUT_FILES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input files\n",
    "\n",
    "REGENIE requires input bgen and sample files. Get the filepaths to the datasets of interest listed here and make a copy in a personal gs bucket: https://support.researchallofus.org/hc/en-us/articles/29475233432212-Controlled-CDR-Directory ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bgen and sample files for ACAF threshold callsets\n",
    "## TODO: replace my_bucket with the actual string\n",
    "! gsutil -u $GOOGLE_PROJECT -m cp -r gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/acaf_threshold_v7.1/bgen/ {my_bucket}/data/dsub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should list .bgen, .bgen.bgi, and .sample files for each chromosome\n",
    "! gsutil ls {my_bucket}/data/dsub/bgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell script for analysis\n",
    "This is the shell script that runs REGENIE.\n",
    "The variable files inputs:\n",
    "\n",
    "- `bgen_file`: the path to the bgen file\n",
    "- `sample_file`: the path the sample file\n",
    "- `pheno_file`: the path to the phenotype file\n",
    "- `cov_file`: the path to the covariate file\n",
    "- `step1_snplist`: input SNPs for step1\n",
    "- `step2_snplist`: input SNPs for step2\n",
    "\n",
    "The environment strings inputs:\n",
    "\n",
    "- `cat_cov`: categorical covariates (comma separated)\n",
    "- `cov_list`: continous covariates (comma separated)\n",
    "- `phen_col`: phenotype as defined by the phenotype column in the phenotype file (name of trait) (comma separated if more than one)\n",
    "- `trait`: qt or bt for quantitative or binary trait\n",
    "- `chrom`: chromosome (automatic from the dsub loop)\n",
    "- `prefix`: desired file prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential modifications\n",
    "Add the `--apply-rint` flag for quantitative traits (i.e., if running EBV DNA without binarizing by our 0.0018 threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/Regenie_GWAS_custom.sh\n",
    "\n",
    "set -o pipefail \n",
    "set -o errexit\n",
    "\n",
    "# step1\n",
    "regenie \\\n",
    "    --step 1 \\\n",
    "    --bgen \"${bgen_file}\" \\\n",
    "    --sample  \"${sample_file}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList \"${phen_col}\" \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --catCovarList sex_at_birth \\\n",
    "    --covarColList age,age2,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15\\\n",
    "    --bsize 1000 \\\n",
    "    --extract \"${step1_snplist}\" \\\n",
    "    --verbose \\\n",
    "    --\"${trait}\" \\\n",
    "    --ref-first \\\n",
    "    --out \"${prefix}\"_step1_chr\"${chrom}\"\n",
    "\n",
    "# step2\n",
    "regenie \\\n",
    "    --step 2 \\\n",
    "    --bgen \"${bgen_file}\" \\\n",
    "    --sample  \"${sample_file}\" \\\n",
    "    --phenoFile \"${pheno_file}\" \\\n",
    "    --phenoColList \"${phen_col}\" \\\n",
    "    --covarFile \"${cov_file}\" \\\n",
    "    --catCovarList sex_at_birth \\\n",
    "    --covarColList age,age2,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,PC11,PC12,PC13,PC14,PC15\\\n",
    "    --pred \"${prefix}\"_step1_chr\"${chrom}\"_pred.list \\\n",
    "    --extract \"${step2_snplist}\" \\\n",
    "    --bsize 400 \\\n",
    "    --verbose \\\n",
    "    --\"${trait}\" \\\n",
    "    --ref-first \\\n",
    "    --out \"${prefix}\"_step2_chr\"${chrom}\"\n",
    "\n",
    "export regenie_results=\"${prefix}_step2_chr${chrom}_${phen_col}.regenie\"\n",
    "echo \"regenie_results: ${regenie_results}\"\n",
    "mv ${regenie_results} ${OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy scripts and inputs into gs bucket\n",
    "Input files must be in a gs bucket for dsub to recognize the pathway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to personal gs bucket\n",
    "! gsutil cp /home/jupyter/Regenie_GWAS_custom.sh {my_bucket}/data/dsub/\n",
    "! gsutil -m cp -r /home/jupyter/workspaces/ebvgwas/AOU_SNPs_EUR {my_bucket}/data/dsub\n",
    "! gsutil -m cp -r /home/jupyter/workspaces/ebvgwas/EBV_GWAS_data/EUR {my_bucket}/data/dsub\n",
    "# Check files are in bucket\n",
    "## NOTE: replace {my_bucket} with the actual string\n",
    "! gsutil ls {my_bucket}/data/dsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run REGENIE\n",
    "\n",
    "This script submits a job for each chromosome in the for loop.\n",
    "\n",
    "Note that the `--disk-size 220` flag only needs to be set when running chr2, as its bgen file is 197 GB and the default of 200 runs out of space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "# Get a shorter username to leave more characters for the job name\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "# For AoU RWB projects network name is \"network\"\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "## TODO: replace {my_bucket} with the actual string\n",
    "MACHINE_TYPE=\"n2-standard-4\"\n",
    "BASH_SCRIPT=\"{my_bucket}/data/dsub/Regenie_GWAS_custom.sh\"\n",
    "\n",
    "# Set the chromosomes of interest\n",
    "## TODO: replace {my_bucket} with the actual string\n",
    "## TODO: make sure the snplists naming format is correct (for example, when running chr2_snplist_2.txt)\n",
    "LOWER=1\n",
    "UPPER=21\n",
    "for ((chromo=$LOWER;chromo<$UPPER;chromo+=1))\n",
    "do\n",
    "    # Print all relevant variables\n",
    "    echo \"GOOGLE_PROJECT: ${GOOGLE_PROJECT}\"\n",
    "    echo \"AOU_NETWORK: ${AOU_NETWORK}\"\n",
    "    echo \"AOU_SUBNETWORK: ${AOU_SUBNETWORK}\"\n",
    "    echo \"DSUB_USER_NAME: ${DSUB_USER_NAME}\"\n",
    "    echo \"MACHINE_TYPE: ${MACHINE_TYPE}\"\n",
    "    echo \"BASH_SCRIPT: ${BASH_SCRIPT}\"\n",
    "    echo \"chromo: ${chromo}\"\n",
    "    echo \"WORKSPACE_BUCKET: ${WORKSPACE_BUCKET}\"\n",
    "    echo \"JOB_NAME: ${JOB_NAME}\"\n",
    "    echo \"OUTPUT_FILES: ${OUTPUT_FILES}\"\n",
    "    echo \"bgen_file: {my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.bgen\"\n",
    "    echo \"sample_file: {my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.sample\"\n",
    "    echo \"pheno_file: {my_bucket}/data/dsub/EUR/ebv_EUR_0018.tsv\"\n",
    "    echo \"cov_file: {my_bucket}/data/dsub/EUR/ebv_EUR_covar.tsv\"\n",
    "    echo \"step1_snplist: {my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\"\n",
    "    echo \"step2_snplist: {my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\"\n",
    "    echo \"phen_col: ${phen_col}\"\n",
    "    echo \"prefix: ${prefix}\"\n",
    "    echo \"trait: ${trait}\"\n",
    "\n",
    "    # Now run the dsub command\n",
    "    dsub \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --image \"gcr.io/bick-aps2/ghcr.io/rgcgithub/regenie/regenie:v3.2.4.gz\" \\\n",
    "    --network \"${AOU_NETWORK}\" \\\n",
    "    --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    \"$@\" \\\n",
    "    --preemptible \\\n",
    "    --boot-disk-size 1000 \\\n",
    "    --disk-size 220 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --input bgen_file=\"{my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.bgen\" \\\n",
    "    --input sample_file=\"{my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.sample\" \\\n",
    "    --input pheno_file=\"{my_bucket}/data/dsub/EUR/ebv_EUR_0018.tsv\" \\\n",
    "    --input cov_file=\"{my_bucket}/data/dsub/EUR/ebv_EUR_covar.tsv\" \\\n",
    "    --input step1_snplist=\"{my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\" \\\n",
    "    --input step2_snplist=\"{my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\" \\\n",
    "    --env chrom=${chromo} \\\n",
    "    --env prefix=EBV_DNA \\\n",
    "    --env trait=bt \\\n",
    "    --env phen_col=has_ebv \\\n",
    "    --output-recursive OUTPUT_PATH=\"${OUTPUT_FILES}/${chromo}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a job can be terminated (sometimes for no apparent reason). Other times, we don't necessarily want to run chromosomes contiguously. In that case, specific chromosomes can be specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "# Get a shorter username to leave more characters for the job name\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "# For AoU RWB projects network name is \"network\"\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "## TODO: replace {my_bucket} with the actual string\n",
    "MACHINE_TYPE=\"n2-standard-4\"\n",
    "BASH_SCRIPT=\"{my_bucket}/data/dsub/Regenie_GWAS_custom.sh\"\n",
    "\n",
    "# Set the chromosomes of interest\n",
    "## TODO: replace {my_bucket} with the actual string\n",
    "## TODO: make sure the snplists naming format is correct (for example, when running chr2_snplist_2.txt)\n",
    "for chromo in 2\n",
    "do\n",
    "    # Print all relevant variables\n",
    "    echo \"GOOGLE_PROJECT: ${GOOGLE_PROJECT}\"\n",
    "    echo \"AOU_NETWORK: ${AOU_NETWORK}\"\n",
    "    echo \"AOU_SUBNETWORK: ${AOU_SUBNETWORK}\"\n",
    "    echo \"DSUB_USER_NAME: ${DSUB_USER_NAME}\"\n",
    "    echo \"MACHINE_TYPE: ${MACHINE_TYPE}\"\n",
    "    echo \"BASH_SCRIPT: ${BASH_SCRIPT}\"\n",
    "    echo \"chromo: ${chromo}\"\n",
    "    echo \"WORKSPACE_BUCKET: ${WORKSPACE_BUCKET}\"\n",
    "    echo \"JOB_NAME: ${JOB_NAME}\"\n",
    "    echo \"OUTPUT_FILES: ${OUTPUT_FILES}\"\n",
    "    echo \"bgen_file: {my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.bgen\"\n",
    "    echo \"sample_file: {my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.sample\"\n",
    "    echo \"pheno_file: {my_bucket}/data/dsub/EUR/ebv_EUR_0018.tsv\"\n",
    "    echo \"cov_file: {my_bucket}/data/dsub/EUR/ebv_EUR_covar.tsv\"\n",
    "    echo \"step1_snplist: {my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\"\n",
    "    echo \"step2_snplist: {my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\"\n",
    "    echo \"phen_col: ${phen_col}\"\n",
    "    echo \"prefix: ${prefix}\"\n",
    "    echo \"trait: ${trait}\"\n",
    "\n",
    "    # Now run the dsub command\n",
    "    dsub \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --user-project \"${GOOGLE_PROJECT}\" \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --image \"gcr.io/bick-aps2/ghcr.io/rgcgithub/regenie/regenie:v3.2.4.gz\" \\\n",
    "    --network \"${AOU_NETWORK}\" \\\n",
    "    --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "    --service-account \"$(gcloud config get-value account)\" \\\n",
    "    --user \"${DSUB_USER_NAME}\" \\\n",
    "    --regions us-central1 \\\n",
    "    --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "    \"$@\" \\\n",
    "    --preemptible \\\n",
    "    --boot-disk-size 1000 \\\n",
    "    --disk-size 220 \\\n",
    "    --machine-type ${MACHINE_TYPE} \\\n",
    "    --name \"${JOB_NAME}\" \\\n",
    "    --script \"${BASH_SCRIPT}\" \\\n",
    "    --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "    --input bgen_file=\"{my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.bgen\" \\\n",
    "    --input sample_file=\"{my_bucket}/data/dsub/bgen/acaf_threshold.chr${chromo}.sample\" \\\n",
    "    --input pheno_file=\"{my_bucket}/data/dsub/EUR/ebv_EUR_0018.tsv\" \\\n",
    "    --input cov_file=\"{my_bucket}/data/dsub/EUR/ebv_EUR_covar.tsv\" \\\n",
    "    --input step1_snplist=\"{my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\" \\\n",
    "    --input step2_snplist=\"{my_bucket}/data/dsub/AOU_SNPs_EUR/chr${chromo}_snplist.txt\" \\\n",
    "    --env chrom=${chromo} \\\n",
    "    --env prefix=EBV_DNA \\\n",
    "    --env trait=bt \\\n",
    "    --env phen_col=has_ebv \\\n",
    "    --output-recursive OUTPUT_PATH=\"${OUTPUT_FILES}/${chromo}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this dsub command prints out things like:\n",
    "```text\n",
    "Job properties:\n",
    "  job-id: ebv-dna--snyeo--250415-142725-88\n",
    "  job-name: ebv-dna\n",
    "  user-id: snyeo\n",
    "Provider internal-id (operation): projects/681565494320/locations/us-central1/operations/12640613304380835749\n",
    "Launched job-id: ebv-dna--snyeo--250415-142725-88\n",
    "To check the status, run:\n",
    "  dstat --provider google-cls-v2 --project terra-vpc-sc-47bdfd92 --location us-central1 --jobs 'ebv-dna--snyeo--250415-142725-88' --users 'snyeo' --status '*'\n",
    "To cancel the job, run:\n",
    "  ddel --provider google-cls-v2 --project terra-vpc-sc-47bdfd92 --location us-central1 --jobs 'ebv-dna--snyeo--250415-142725-88' --users 'snyeo'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor dsub job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of current job(s) status\n",
    "## TODO: replace jobs with the job-id printed above \n",
    "## TODO: replace users with the user-id\n",
    "! dstat \\\n",
    "        --provider google-cls-v2 \\\n",
    "        --project terra-vpc-sc-47bdfd92 \\\n",
    "        --location us-central1 \\\n",
    "        --jobs 'ebv-dna--snyeo--250416-125527-75' \\\n",
    "        --users 'snyeo' \\\n",
    "        --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints something like:\n",
    "```text\n",
    "Job Name    Status    Last Update\n",
    "----------  --------  --------------\n",
    "ebv-dna     Success   04-16 18:05:06\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full summary of current job(s) status\n",
    "! dstat \\\n",
    "        --provider google-cls-v2 \\\n",
    "        --project terra-vpc-sc-47bdfd92 \\\n",
    "        --location us-central1 \\\n",
    "        --jobs 'ebv-dna--snyeo--250416-125527-75' \\\n",
    "        --users 'snyeo' \\\n",
    "        --status '*' \\\n",
    "        --full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints something like:\n",
    "```text\n",
    "- create-time: '2025-04-16 12:55:27.911982'\n",
    "  dsub-version: v0-5-0\n",
    "  end-time: ''\n",
    "  envs:\n",
    "    GOOGLE_PROJECT: terra-vpc-sc-47bdfd92\n",
    "    chrom: '2'\n",
    "    phen_col: has_ebv\n",
    "    prefix: EBV_DNA\n",
    "    trait: bt\n",
    "  events:\n",
    "  - name: start\n",
    "    start-time: 2025-04-16 12:55:42.756543+00:00\n",
    "  - name: pulling-image\n",
    "    start-time: 2025-04-16 12:56:24.834398+00:00\n",
    "  - name: localizing-files\n",
    "    start-time: 2025-04-16 12:56:37.460297+00:00\n",
    "  - name: running-docker\n",
    "    start-time: 2025-04-16 13:48:37.851483+00:00\n",
    "  input-recursives: {}\n",
    "  inputs:\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the log file(s) outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print last five lines\n",
    "## TODO: replace log file filepath with what's printed in the full summary\n",
    "! gsutil cat gs://fc-secure-44d65cda-9cdd-49bc-b829-a681f3123cfa/dsub/logs/ebv-dna/snyeo/20250416/125526/ebv-dna--snyeo--250416-125527-75-task-None.log | tail -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n",
    "\n",
    "Copy over the log file(s) and the .regenie output file(s) to the local workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy log file\n",
    "## TODO: replace log file filepath with what's printed in the full summary\n",
    "! gsutil cp gs://fc-secure-44d65cda-9cdd-49bc-b829-a681f3123cfa/dsub/logs/ebv-dna/snyeo/20250416/125526/ebv-dna--snyeo--250416-125527-75-task-None.log ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy REGENIE output file (will be listed in the log file)\n",
    "! gsutil cp gs://fc-secure-44d65cda-9cdd-49bc-b829-a681f3123cfa/dsub/results/EBV_DNA/snyeo/20250412/results/1/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip REGENIE files to save space: `gzip *.regenie`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanpyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
